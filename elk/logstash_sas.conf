input {
  file {
    # input for sas user logs.
    path => "/sas/eg/Lev1/Logs/ObjectSpawner_*"
    start_position => "beginning"
    type => "sas-objectspawner"
    codec => multiline {
      pattern => "^%{TIMESTAMP_ISO8601}"
      negate => true
      what => "previous"
    }
  }
  file {
      path => "/var/log/messages"
      type => "syslog"
  }
}
filter {
    if [type] == "syslog" {
	grok {
	    match => { "message" => "%{SYSLOGTIMESTAMP:timestamp} %{SYSLOGHOST:hostname} %{DATA:program}(?:\[%{POSINT:pid}\])?: %{GREEDYDATA:msg}" }
	}
	date { 
	     match => [ "timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ] 
	     target => "@timestamp"
	}
    }
    if [type] == "sas-objectspawner" {
       grok { match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:loglevel}  %{NOTSPACE} :%{USERNAME:user} - %{SPACE}*%{GREEDYDATA:msg}" }}
       date { 
           match => ["timestamp", "yyyy-MM-dd HH:mm:ss,SSS", "ISO8601"]
	   target => "@timestamp" # so that we can have the time-filed on kibana
       }
    }
    
    mutate {remove_field => ["timestamp", "@version", "path", "message", "_type"]}

    # Drop the message with parse errors.
    if "_grokparsefailure" in [tags] {
       drop { }
    }
}
output {
    if [type] == "syslog" {
       elasticsearch { 
           hosts => ["localhost"] 
       }
    }
    if [type] == "sas-objectspawner" {
        elasticsearch {
	    hosts => ["localhost"]
	    index => "sas-objectspawner"
	}
    }
    # stdout { codec => rubydebug }
}

input {
  file {
    path => "/var/log/hive/hadoop-cmf-hive-HIVESERVER2-*"
    start_position => "beginning"
    type => "hiveserver"
    codec => multiline {
      pattern => "^%{TIMESTAMP_ISO8601}"
      negate => true
      what => "previous"
    }
  }
  file {
    # Input for hive metastore server logs
    path => "/var/log/hive/hadoop-cmf-hive-HIVEMETASTORE-*"
    start_position => "beginning"
    type => "hivemetastore"
    codec => multiline {
      pattern => "^%{TIMESTAMP_ISO8601}"
      negate => true
      what => "previous"
    }
  }

  file {
      path => "/var/log/messages"
      type => "syslog"
  }
}
filter {
    if [type] == "syslog" {
	grok {
	    match => { "message" => "%{SYSLOGTIMESTAMP:timestamp} %{SYSLOGHOST:hostname} %{DATA:program}(?:\[%{POSINT:pid}\])?: %{GREEDYDATA:msg}" }
	    add_field => [ "received_at", "%{@timestamp}" ]
	    add_field => [ "received_from", "%{host}" ]
	}
	pri { }
	date { match => [ "timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ] }

    }
    if [type] in ["hiveserver", "hivemetastore"] {
       # mutate { add_field => { "ingest_timestamp" => "%{@timestamp}" } } 
       grok { match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:loglevel}  ?%{GREEDYDATA:class}: \[%{DATA:thread}\]: %{GREEDYDATA:msg}" }}
       date { 
           match => ["timestamp", "yyyy-MM-dd HH:mm:ss,SSS", "ISO8601"]
	   target => "@timestamp" # so that we can have the time-filed on kibana
       }
       mutate {remove_field => ["timestamp", "@version", "path", "message", "_type"]}
    }
}
output {
    if [type] == "syslog" {
       elasticsearch { 
           hosts => ["usalthdbdl01"] 
       }
    }
    if [type] == "hiveserver" {
        elasticsearch {
	    hosts => ["localhost"]
	    index => "hadoop-hiveserver"
	}
    }
    if [type] == "hivemetastore" {
       elasticsearch {
           hosts => ["localhost"]
	   index => "hadoop-hivemetastore"
       }
    }
    # stdout { codec => rubydebug }
}
